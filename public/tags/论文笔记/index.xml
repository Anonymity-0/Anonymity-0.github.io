<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>论文笔记 on AGA&#39;s Blog</title>
        <link>https://anonymity-0.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</link>
        <description>Recent content in 论文笔记 on AGA&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <copyright>AGA</copyright>
        <lastBuildDate>Wed, 20 Dec 2023 22:51:25 +0800</lastBuildDate><atom:link href="https://anonymity-0.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Portland</title>
        <link>https://anonymity-0.github.io/posts/portland/</link>
        <pubDate>Wed, 20 Dec 2023 22:51:25 +0800</pubDate>
        
        <guid>https://anonymity-0.github.io/posts/portland/</guid>
        <description>&lt;h1 id=&#34;portland-a-scalable-fault-tolerant-layer-2-data-center-network-fabric&#34;&gt;PortLand: a scalable fault-tolerant layer 2 data center network fabric&lt;/h1&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-meta-data&#34;&gt;💡 Meta Data&lt;/h2&gt;
&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;th style=&#34;background-color: rgb(219, 238, 221);&#34;&gt;&lt;p style=&#34;text-align: left&#34;&gt;&lt;span style=&#34;background-color: #dbeedd&#34;&gt;Title&lt;/span&gt;&lt;/p&gt;&lt;/th&gt;&lt;td style=&#34;background-color: rgb(219, 238, 221);&#34;&gt;&lt;p&gt;&lt;span style=&#34;background-color: #dbeedd&#34;&gt;PortLand: a scalable fault-tolerant layer 2 data center network fabric&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th style=&#34;background-color: rgb(243, 250, 244);&#34;&gt;&lt;p style=&#34;text-align: left&#34;&gt;&lt;span style=&#34;background-color: #f3faf4&#34;&gt;Journal&lt;/span&gt;&lt;/p&gt;&lt;/th&gt;&lt;td style=&#34;background-color: rgb(243, 250, 244);&#34;&gt;&lt;p&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th style=&#34;background-color: rgb(219, 238, 221);&#34;&gt;&lt;p style=&#34;text-align: left&#34;&gt;&lt;span style=&#34;background-color: #dbeedd&#34;&gt;Authors&lt;/span&gt;&lt;/p&gt;&lt;/th&gt;&lt;td style=&#34;background-color: rgb(219, 238, 221);&#34;&gt;&lt;p&gt;&lt;span style=&#34;background-color: #dbeedd&#34;&gt;Radhika Niranjan Mysore; Andreas Pamboris; Nathan Farrington; Nelson Huang; Pardis Miri; Sivasankar Radhakrishnan; Vikram Subramanya; Amin Vahdat&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th style=&#34;background-color: rgb(243, 250, 244);&#34;&gt;&lt;p style=&#34;text-align: left&#34;&gt;&lt;span style=&#34;background-color: #f3faf4&#34;&gt;Pub. date&lt;/span&gt;&lt;/p&gt;&lt;/th&gt;&lt;td style=&#34;background-color: rgb(243, 250, 244);&#34;&gt;&lt;p&gt;&lt;span style=&#34;background-color: #f3faf4&#34;&gt;八月 16, 2009&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th style=&#34;background-color: rgb(219, 238, 221);&#34;&gt;&lt;p style=&#34;text-align: left&#34;&gt;&lt;span style=&#34;background-color: #dbeedd&#34;&gt;期刊标签&lt;/span&gt;&lt;/p&gt;&lt;/th&gt;&lt;td style=&#34;background-color: rgb(219, 238, 221);&#34;&gt;&lt;p&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th style=&#34;background-color: rgb(243, 250, 244);&#34;&gt;&lt;p style=&#34;text-align: left&#34;&gt;&lt;span style=&#34;background-color: #f3faf4&#34;&gt;DOI&lt;/span&gt;&lt;/p&gt;&lt;/th&gt;&lt;td style=&#34;background-color: rgb(243, 250, 244);&#34;&gt;&lt;p&gt;&lt;span style=&#34;background-color: #f3faf4&#34;&gt;&lt;a href=&#34;https://doi.org/10.1145/1592568.1592575&#34; rel=&#34;noopener noreferrer nofollow&#34;&gt;10.1145/1592568.1592575&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th style=&#34;background-color: rgb(219, 238, 221);&#34;&gt;&lt;p style=&#34;text-align: left&#34;&gt;&lt;span style=&#34;background-color: #dbeedd&#34;&gt;附件&lt;/span&gt;&lt;/p&gt;&lt;/th&gt;&lt;td style=&#34;background-color: rgb(219, 238, 221);&#34;&gt;&lt;p&gt;&lt;span style=&#34;background-color: #dbeedd&#34;&gt;&lt;a href=&#34;zotero://open-pdf/0_LESYP9QN&#34; rel=&#34;noopener noreferrer nofollow&#34;&gt;Niranjan Mysore 等 - 2009 - PortLand a scalable fault-tolerant layer 2 data c.pdf&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id=&#34;-研究背景--基础--目的&#34;&gt;📜 研究背景 &amp;amp; 基础 &amp;amp; 目的&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;这篇论文的研究背景是针对日益增长的数据中心网络中存在的限制和挑战，例如在现有的层2和层3网络协议在支持大规模数据中心中的灵活性、效率和容错性方面存在的局限性 在笔者提出的论文中，研究的基础是现有网络协议在面临未来单个站点拥有数百万虚拟终端的数据中心时所面临的挑战，特别是关注于如何在这种大规模环境中实现可扩展、易管理、容错和高效的数据中心网络结构&lt;/p&gt;
&lt;p&gt;论文的目的是设计和实现一种名为PortLand的协议，该协议旨在解决现有网络在数据中心部署中的局限性，通过提供一种可扩展、容错、并适用于数据中心环境的层2路由和转发协议通过PortLand协议的设计和实施，论文的目的是展示该协议能够支持“即插即用”的大规模数据中心网络，并为数据中心网络提供更灵活、高效和容错的解决方案&lt;/p&gt;
&lt;p&gt;ARP是地址解析协议（Address Resolution Protocol），用于将IP地址映射成对应的MAC地址的协议。在局域网中，当一台设备需要发送数据给另一台设备时，它会使用ARP来获取目标设备的MAC地址，以便将数据发送到正确的目标。ARP协议在以太网和其他局域网技术中广泛使用。&lt;/p&gt;
&lt;h2 id=&#34;-研究内容&#34;&gt;📊 研究内容&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;PMAC是如何设计的&lt;/strong&gt;&lt;br&gt;
PMAC（Pseudo MAC）地址的设计是基于一种层次化的编码方式。在PortLand中，每个主机被分配一个唯一的PMAC地址，该地址编码了主机在拓扑结构上的位置。例如，在同一个pod中的所有终节点的PMAC地址具有相同的前缀。主机保持不变，认为它们仍然使用其实际的MAC地址（AMAC）。当主机发送ARP请求时，它们接收到目标主机的PMAC地址[5a]。所有的数据包转发都是基于PMAC地址进行的，这样可以实现非常小的转发表。发送数据包时，出口交换机会对PMAC地址进行重写，将其转换为目标主机的AMAC地址，以保持主机不变的MAC地址的幻象。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.58jtvgee9ds0.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;步骤1：当入口交换机首次看到源MAC地址时，会将数据包传送到交换机。&lt;/p&gt;
&lt;p&gt;步骤2a：软件在本地PMAC表中创建一个条目，将主机的AMAC和IP地址映射到其PMAC。边缘交换机决定PMAC。&lt;/p&gt;
&lt;p&gt;步骤2b：交换机将此映射通信给“Fabric Manager”。&lt;/p&gt;
&lt;p&gt;步骤3：“Fabric Manager”使用此状态来响应ARP请求。交换机还会创建适当的流表条目，将 PMAC 目标地址重写为 AMAC，以便对任何发送到主机的流量重写PMAC目的地地址。&lt;/p&gt;
&lt;h3 id=&#34;proxy-based-arp&#34;&gt;Proxy-based ARP&lt;/h3&gt;
&lt;p&gt;“Ethernet by default broadcasts ARPs to all hosts in the same layer 2 domain. We leverage the fabric manager to reduce broadcast overhead in the common case, as depicted in Figure 3. In step 1, an edge switch intercepts an ARP request for an IP to MAC address mapping and forwards the request to the fabric manager in step 2. The fabric manager consults its PMAC table to see if an entry is available for the target IP address. If so, it returns the PMAC in step 3 to the edge switch. The edge switch creates an ARP reply in step 4 and returns it to the original host.” (Niranjan Mysore 等, 2009, p. 43) 🔤以太网默认情况下会向同一第 2 层域中的所有主机广播 ARP。如图 3 所示，我们利用结构管理器来减少普通情况下的广播开销。在步骤 1 中，边缘交换机拦截 IP 到 MAC 地址映射的 ARP 请求，并在步骤 2 中将请求转发给结构管理器。Fabric 管理器会查询其 PMAC 表，查看是否有目标 IP 地址的条目。如果有，它会在步骤 3 中将 PMAC 返回给边缘交换机。边缘交换机在步骤 4 中创建 ARP 回复，并将其返回给原始主机。🔤&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.6pnerd5w0tc0.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;步骤1-2：边缘交换机拦截针对IP到MAC地址映射的ARP请求，并将请求转发给布线管理器。&lt;strong&gt;ARP请求不被广播&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;步骤3：布线管理器查询其PMAC表，查看目标IP地址是否有条目可用。如果有，则返回PMAC给边缘交换机。&lt;/p&gt;
&lt;p&gt;步骤4：边缘交换机创建ARP响应，并将其返回给原始主机。&lt;/p&gt;
&lt;p&gt;“Note that end hosts receive PMACs in response to an ARP request and that all packet forwarding proceeds based on the hierarchical PMAC. The egress switch performs PMAC to AMAC rewriting only on the last hop to the destination host.” (Niranjan Mysore 等, 2009, p. 43)&lt;/p&gt;
&lt;p&gt;PMAC是针对ARP请求的应答而接收到的，所有数据包转发都是根据层次式PMAC进行的。出口交换机只在最后一跳到达目标主机时才执行PMAC到AMAC的重写。&lt;/p&gt;
&lt;h3 id=&#34;distributed-location-discovery&#34;&gt;Distributed Location Discovery&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;LDP&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;“we also present a location discovery protocol (LDP) that requires no administrator configuration. PortLand switches do not begin packet forwarding until their location is established.” (Niranjan Mysore 等, 2009, p. 44) 🔤我们还介绍了一种无需管理员配置的位置发现协议（LDP）。在确定位置之前，PortLand 交换机不会开始转发数据包。🔤&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LDM&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;“PortLand switches periodically send a Location Discovery Message (LDM) out all of their ports both, to set their positions and to monitor liveness in steady state. LDMs contain the following information:” (Niranjan Mysore 等, 2009, p. 44) 🔤PortLand 交换机会定期向其所有端口发送位置发现信息（LDM），以设置其位置并监控稳定状态下的有效性。LDM 包含以下信息：🔤&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;交换机标识符（switch id）：每个交换机的全局唯一标识符，如所有本地端口的最低 MAC 地址。&lt;/li&gt;
&lt;li&gt;pod 号码（pod）：同一 pod 中所有交换机共享的号码（见图 1）。不同 pod 中的交换机将有不同的 pod 编号。核心交换机从不设置此值。&lt;/li&gt;
&lt;li&gt;位置 (pos)：分配给每个边缘交换机的编号，在每个 pod 中都是唯一的。&lt;/li&gt;
&lt;li&gt;树级别（level）：0、1 或 2，取决于交换机是边缘交换机、汇聚交换机还是核心交换机。我们的方法适用于更深的层次结构。&lt;/li&gt;
&lt;li&gt;向上/向下（dir）：Up/down（向上/向下）是一个位，表示交换机端口在多根树中的朝向是向下还是向上。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.77l4xh96qik0.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;行7:如果一个交换机在足够长的时间内没有连接到超过 k/2 个邻居交换机，则它是边缘交换机。行8:incoming_port up 在接收到任何后续的LDM时，边缘交换机推断相应的入站端口是一个朝上的端口。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;行10、11:交换机在上行端口上接收到来自边缘交换机的 LDM 时，会断定自己一定是聚合交换机，而且相应的传入端口是下行端口。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;行12-13:&amp;ldquo;第12-13行处理核心/聚合交换机向尚未设置部分端口方向的聚合/边缘交换机传输LDMS的情况。&amp;ldquo;行14:核心交换机的验证首先要验证其所有活动端口都已连接到其他 PortLand 交换机&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;行15-18:然后在第 15-18 行中验证所有邻居都是尚未设置链接方向的汇聚交换机（连接到边缘交换机的汇聚交换机端口已被确定为朝下）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;行20:如果这些条件成立，交换机就可以断定自己是核心交换机，并将其所有端口设置为向下。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;如算法 1 第 2-4 行和第 29 行所示，在多个位置号码同时被提议的情况下，聚合交换机会将提议的位置号码保留一段时间，然后再计时。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;起初，除了交换机标识符和端口号外，其他所有值都是未知的。&lt;/p&gt;
&lt;p&gt;我们假设所有交换机端口都处于三种状态之一：断开、连接到终端主机或连接到另一台交换机。&lt;/p&gt;
&lt;p&gt;“Edge switches learn their level by determining that some fraction of their ports are host connected.” 🔤边缘交换机通过确定其部分端口已连接主机来了解其等级。🔤&lt;/p&gt;
&lt;p&gt;“Level assignment then flows up the tree. Aggregations switches set their level once they learn that some of their ports are connected to edge switches.” 🔤然后，级别分配会沿着树向上流动。汇聚交换机在得知其部分端口连接到边缘交换机后，就会设置自己的级别。🔤&lt;/p&gt;
&lt;p&gt;“Finally, core switches learn their levels once they confirm that all ports are connected to aggregation switches.” 🔤最后，核心交换机在确认所有端口都连接到汇聚交换机后，就会学习其级别。🔤&lt;/p&gt;
&lt;h3 id=&#34;provably-loop-free-forwarding&#34;&gt;Provably Loop Free Forwarding&lt;/h3&gt;
&lt;p&gt;交换机使用 LDP 建立本地位置后，就会利用来自邻居的更新来填充转发表。&lt;/p&gt;
&lt;p&gt;核心交换机会了解直接连接的汇聚交换机的 pod 编号。转发数据包时，核心交换机只需检查 PMAC 目标地址中与 pod 编号相对应的位，即可确定适当的输出端口。&lt;/p&gt;
&lt;p&gt;汇聚交换机也会了解所有直接连接的边缘交换机的位置编号。汇聚交换机必须通过检查 PMAC 来确定数据包的目的地是同一 pod 中的主机还是不同 pod 中的主机。如果在同一 pod 中，则必须将数据包转发到与 PMAC 中位置条目相对应的输出端口。&lt;/p&gt;
&lt;p&gt;如果在不同的 pod 中，在无故障的情况下，数据包可以沿着汇聚交换机的任何链路转发到核心层。为实现负载平衡，交换机可采用多种技术选择合适的输出端口。Fabric 管理器将采用额外的流量表项来覆盖单个流量的默认转发行为。不过，这一决定与本工作无关，因此我们假定采用标准技术，如 ECMP 中的流量散列技术[16]。&lt;/p&gt;
&lt;p&gt;我们的转发协议通过观察上行-下行语义[26]可证明是无环的，数据包将总是被转发至聚合交换机或核心交换机，然后向其最终目的地下行传输。我们通过确保一旦数据包开始向下传输，便不可能向拓扑结构的上行传输，以防止瞬时环路和广播风暴。&lt;/p&gt;
&lt;h3 id=&#34;fault-tolerant-routing&#34;&gt;“Fault Tolerant Routing”&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.wqfmfdicnr4.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;步骤1：如果在一段可配置的时间内没有接收到LDM(在此上下文中也称为keepalive)，交换机将在步骤1中假定链路发生故障。&lt;/p&gt;
&lt;p&gt;步骤2:检测交换机将故障通知fabric管理器。&lt;/p&gt;
&lt;p&gt;步骤3:fabric管理器维护一个包含整个拓扑的每链路连接信息的逻辑故障矩阵，并用新信息更新它。&lt;/p&gt;
&lt;p&gt;步骤4:最后，在步骤4中，fabric管理器将故障通知所有受影响的交换机，然后这些交换机根据新版本的拓扑分别重新计算它们的转发表。&lt;/p&gt;
&lt;p&gt;“Required state for network connectivity is modest, growing with k3/2 for a fully-configured fat tree built from k-port switches.” (Niranjan Mysore 等, 2009, p. 45) 网络连接所需的状态是适度的，对于由k端口交换机构建的完全配置的胖树来说，它随着k3/2的增长而增长。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.4sshadtqs2a0.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;fault-tolerant-routing-for-multicast&#34;&gt;Fault Tolerant Routing for Multicast&lt;/h3&gt;
&lt;p&gt;现在我们考虑组播和广播情况下的容错。相对于现有的协议，我们考虑的故障场景是，没有一个单一的生成树植根于一个核心交换机，能够覆盖一个多播组或广播会话的所有接收器。考虑图5中的示例。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.5hddjlvc5o00.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;在这里，我们有一个多播组映射到最左边的核心交换机。有三个接收器，分布在0号pod和1号pod（图中三个R）。发送端将数据包转发到指定的核心交换机，核心交换机再将数据包分发给接收端。&lt;/p&gt;
&lt;p&gt;步骤1：在步骤1中，pod 0中两个突出显示的链接同时失败。&lt;/p&gt;
&lt;p&gt;步骤2:两个汇聚交换机检测到故障并通知fabric管理器&lt;/p&gt;
&lt;p&gt;步骤3:fabric管理器更新其故障矩阵。&lt;/p&gt;
&lt;p&gt;步骤4:fabric管理器计算所有受影响的多播组的转发表项。&lt;/p&gt;
&lt;p&gt;步骤5:我们通过计算与每个多播组相关联的接收器集的贪婪集覆盖来处理这种情况。这可能导致多个指定的核心交换机与多播或广播组相关联。fabric管理器在图5的步骤5中将所需的转发状态插入到适当的表中。&lt;/p&gt;
&lt;p&gt;从故障中恢复需要通过pod 0中的两个单独的聚合交换机进行转发。但是，不存在同时连接两个汇聚交换机的单核交换机。&lt;/p&gt;
&lt;h2 id=&#34;-研究结论&#34;&gt;🚩 研究结论&lt;/h2&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-感想--疑问&#34;&gt;📌 感想 &amp;amp; 疑问&lt;/h2&gt;
&lt;hr&gt;
&lt;h3 id=&#34;why-existing-l2-and-l3-techniques-can-not-satisfy-r1-5-for-the-cloud-datacenter&#34;&gt;Why existing L2 and L3 techniques can not satisfy  R1-5 for the cloud datacenter?&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;单一网络结构（R1和R2）：&lt;/strong&gt; 云数据中心要求整个数据中心使用一个相同的网络结构，但L3技术需要为每个交换机配置子网信息，而L2技术由于需要支持广播而面临效率和可扩展性的挑战。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;透明虚拟机迁移（R3）：&lt;/strong&gt; 在L3中，虚拟机迁移到不同子网的主机时需要切换IP地址，这导致透明的迁移变得不可能。而L2的MAC表也面临着在硬件上不切实际的问题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;转发环路问题（R4）：&lt;/strong&gt; 无论是L2还是L3，在路由收敛期间都可能发生转发环路问题，这在设计上很困难。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高效路由协议（R5）：&lt;/strong&gt; 要求一种能够快速传播拓扑变化的高效路由协议，但现有的L2和L3协议都是基于广播的，效率不高。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;what-is-pmac-address&#34;&gt;What is PMAC address?、&lt;/h3&gt;
&lt;p&gt;PMAC（Pseudo MAC）地址是PortLand网络设计中使用的一种地址。每个终端主机在PortLand中被分配了一个唯一的PMAC地址，用于编码该主机在网络拓扑中的位置。PMAC地址使得路由转发和虚拟机迁移变得高效。终端主机保持其实际的MAC（AMAC）地址不变，不知道自己被分配了一个PMAC地址。在进行ARP请求时，源主机会收到目标主机的PMAC地址。所有的数据包转发都基于PMAC地址进行，这样可以实现非常小的转发表。出口交换机会对PMAC地址进行转换，以保持目标主机的MAC地址不变。&lt;/p&gt;
&lt;h3 id=&#34;location-discovery&#34;&gt;Location discovery.&lt;/h3&gt;
&lt;p&gt;位置发现是指在网络中确定设备的位置的过程。根据提供的上下文信息[2]，PortLand使用一种轻量级协议来帮助交换机发现其在拓扑中的位置。交换机通过接收LDM（Link Detection Message）来了解其邻居交换机的信息，通过判断与多少个邻居交换机相连来确定是否为边缘交换机。边缘交换机通常有一半以上的端口连接到终端设备。在确认自己是边缘交换机后，交换机可以通过在所有端口上进行PING操作来进一步确认其位置。终端设备将回复PING请求，而不会发送LDM。&lt;/p&gt;
&lt;h3 id=&#34;how-portland-satisfies-r1--r5&#34;&gt;How PortLand satisfies R1 – R5?&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;R1: VM can migrate, introduce PMAC&lt;/li&gt;
&lt;li&gt;R2: no configuration, LDP protocol&lt;/li&gt;
&lt;li&gt;R3: use all equal cost paths, ECMP&lt;/li&gt;
&lt;li&gt;R4: no loop&lt;/li&gt;
&lt;li&gt;R5: failure-tolerant, fabric manager&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;PortLand满足R1-R5的方式如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;R1: 虚拟机迁移和引入PMAC：&lt;/strong&gt; PortLand允许虚拟机迁移，并引入了PMAC（Persistent MAC）来保持虚拟机在不同子网上的IP地址不变，实现了透明的虚拟机迁移。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;R2: 无需配置和LDP协议：&lt;/strong&gt; PortLand不需要在每个交换机上进行繁琐的配置，而是使用了LDP（Label Distribution Protocol）协议，简化了网络管理的复杂性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;R3: 使用所有等价路径和ECMP：&lt;/strong&gt; 为了实现更好的负载均衡和性能，PortLand利用ECMP（Equal Cost Multipath）使用所有等价路径，确保数据流可以通过多条路径传输，提高网络利用率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;R4: 无环路：&lt;/strong&gt; PortLand设计中考虑了防止转发环路的问题，确保在网络路由收敛时不会出现不必要的循环。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;R5: 容错性强，有Fabric Manager：&lt;/strong&gt; PortLand具备故障容忍性，通过Fabric Manager进行管理，确保在网络中出现故障时可以及时调整和修复，提高了网络的可靠性和稳定性。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;是的，这篇文章使用了伪MAC地址（PMAC）技术。&lt;/p&gt;
&lt;h2 id=&#34;-理论推导&#34;&gt;🔬 理论推导&lt;/h2&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>Fat Tree</title>
        <link>https://anonymity-0.github.io/posts/fat-tree/</link>
        <pubDate>Tue, 19 Dec 2023 15:45:19 +0800</pubDate>
        
        <guid>https://anonymity-0.github.io/posts/fat-tree/</guid>
        <description>&lt;p&gt;A scalable, commodity data center network architecture&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-meta-data&#34;&gt;💡 Meta Data&lt;/h2&gt;
&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;th style=&#34;background-color: rgb(219, 238, 221);&#34;&gt;&lt;p style=&#34;text-align: left&#34;&gt;&lt;span style=&#34;background-color: #dbeedd&#34;&gt;Title&lt;/span&gt;&lt;/p&gt;&lt;/th&gt;&lt;td style=&#34;background-color: rgb(219, 238, 221);&#34;&gt;&lt;p&gt;&lt;span style=&#34;background-color: #dbeedd&#34;&gt;A scalable, commodity data center network architecture&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th style=&#34;background-color: rgb(243, 250, 244);&#34;&gt;&lt;p style=&#34;text-align: left&#34;&gt;&lt;span style=&#34;background-color: #f3faf4&#34;&gt;Journal&lt;/span&gt;&lt;/p&gt;&lt;/th&gt;&lt;td style=&#34;background-color: rgb(243, 250, 244);&#34;&gt;&lt;p&gt;&lt;span style=&#34;background-color: #f3faf4&#34;&gt;ACM SIGCOMM Computer Communication Review&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th style=&#34;background-color: rgb(219, 238, 221);&#34;&gt;&lt;p style=&#34;text-align: left&#34;&gt;&lt;span style=&#34;background-color: #dbeedd&#34;&gt;Authors&lt;/span&gt;&lt;/p&gt;&lt;/th&gt;&lt;td style=&#34;background-color: rgb(219, 238, 221);&#34;&gt;&lt;p&gt;&lt;span style=&#34;background-color: #dbeedd&#34;&gt;Mohammad Al-Fares; Alexander Loukissas; Amin Vahdat&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th style=&#34;background-color: rgb(243, 250, 244);&#34;&gt;&lt;p style=&#34;text-align: left&#34;&gt;&lt;span style=&#34;background-color: #f3faf4&#34;&gt;Pub. date&lt;/span&gt;&lt;/p&gt;&lt;/th&gt;&lt;td style=&#34;background-color: rgb(243, 250, 244);&#34;&gt;&lt;p&gt;&lt;span style=&#34;background-color: #f3faf4&#34;&gt;八月 17, 2008&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th style=&#34;background-color: rgb(219, 238, 221);&#34;&gt;&lt;p style=&#34;text-align: left&#34;&gt;&lt;span style=&#34;background-color: #dbeedd&#34;&gt;期刊标签&lt;/span&gt;&lt;/p&gt;&lt;/th&gt;&lt;td style=&#34;background-color: rgb(219, 238, 221);&#34;&gt;&lt;p&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th style=&#34;background-color: rgb(243, 250, 244);&#34;&gt;&lt;p style=&#34;text-align: left&#34;&gt;&lt;span style=&#34;background-color: #f3faf4&#34;&gt;DOI&lt;/span&gt;&lt;/p&gt;&lt;/th&gt;&lt;td style=&#34;background-color: rgb(243, 250, 244);&#34;&gt;&lt;p&gt;&lt;span style=&#34;background-color: #f3faf4&#34;&gt;&lt;a href=&#34;https://doi.org/10.1145/1402946.1402967&#34; rel=&#34;noopener noreferrer nofollow&#34;&gt;10.1145/1402946.1402967&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th style=&#34;background-color: rgb(219, 238, 221);&#34;&gt;&lt;p style=&#34;text-align: left&#34;&gt;&lt;span style=&#34;background-color: #dbeedd&#34;&gt;附件&lt;/span&gt;&lt;/p&gt;&lt;/th&gt;&lt;td style=&#34;background-color: rgb(219, 238, 221);&#34;&gt;&lt;p&gt;&lt;span style=&#34;background-color: #dbeedd&#34;&gt;&lt;a href=&#34;zotero://open-pdf/0_288AB75H&#34; rel=&#34;noopener noreferrer nofollow&#34;&gt;Al-Fares et al_2008_A scalable, commodity data center network architecture.pdf&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id=&#34;-研究背景--基础--目的&#34;&gt;📜 研究背景 &amp;amp; 基础 &amp;amp; 目的&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;“Clusters consisting of tens of thousands of PCs are not unheard of in the largest “institutions and thousand-node clusters are increasingly common in universities, research labs, and companies.”  (Al-Fares 等, 2008, p. 63) 大型机构中由数万台PC组成的集群并不少见，在大学，研究实验室和公司中，千节点集群越来越普遍。这些集群用于各种目的，包括科学计算，数据分析和机器学习。它们提供了大量的计算能力，可用于解决复杂问题。&lt;/p&gt;
&lt;h3 id=&#34;dc-communications&#34;&gt;DC Communications&lt;/h3&gt;
&lt;p&gt;M2M communications：M2M communications，即机器对机器通信，是指机器与机器之间进行的数据通信。M2M通信的目的通常是实现机器之间的自动化控制和数据交换。&lt;/p&gt;
&lt;p&gt;“Today, the principle bottleneck in large-scale clusters is often inter-node communication bandwidth.” (Al-Fares 等, 2008, p. 63) 如今，大规模集群的主要瓶颈往往是节点间的通信带宽。&lt;/p&gt;
&lt;p&gt;“For example, MapReduce [12] must perform significant data shuffling to transport the output of its map phase before proceeding with its reduce phase. Applications running on clusterbased file systems [18, 28, 13, 26] often require remote-node access before proceeding with their I/O operations.” (Al-Fares 等, 2008, p. 63) 例如，MapReduce必须先进行大量的数据重组，以传输其映射阶段的输出，然后再进入还原阶段。在基于集群的文件系统上运行的应用程序在进行 I/O 操作前，通常需要远程节点访问。&lt;/p&gt;
&lt;p&gt;“A query to a web search engine often requires parallel communication with every node in the cluster hosting the inverted index to return the most relevant results [7].” (Al-Fares 等, 2008, p. 63) 🔤对网络搜索引擎的查询往往需要与承载倒排索引的集群中的每个节点进行并行通信，以返回最相关的结果[7]。🔤&lt;/p&gt;
&lt;p&gt;“Internet services increasingly employ service oriented architectures [13], where the retrieval of a single web page can require coordination and communication with literally hundreds of individual sub-services running on remote nodes.” (Al-Fares 等, 2008, p. 63) 🔤互联网服务越来越多地采用面向服务的架构[13]，在这种架构下，检索一个网页可能需要与远程节点上运行的数百个单独的子服务进行协调和通信。🔤&lt;/p&gt;
&lt;h3 id=&#34;two-approaches-for-dc-network&#34;&gt;Two approaches for DC network&lt;/h3&gt;
&lt;p&gt;“There are two high-level choices for building the communication fabric for large-scale clusters.”&lt;/p&gt;
&lt;h4 id=&#34;approach1&#34;&gt;approach1&lt;/h4&gt;
&lt;p&gt;“One option leverages specialized hardware and communication protocols, such as InfiniBand [2] or Myrinet [6].” (Al-Fares 等, 2008, p. 63) 🔤一种方法是利用专用硬件和通信协议，如 InfiniBand [2] 或 Myrinet [6]。🔤&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;“they do not leverage commodity parts (and are hence more expensive)” (Al-Fares 等, 2008, p. 63)&lt;strong&gt;它们不使用通用零件（因此更昂贵）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;“not natively compatible with TCP/IP applications.” (Al-Fares 等, 2008, p. 63) 🔤与 TCP/IP 应用程序不兼容。🔤&lt;/p&gt;
&lt;h4 id=&#34;approach2&#34;&gt;approach2&lt;/h4&gt;
&lt;p&gt;“The second choice leverages commodity Ethernet switches and routers to interconnect cluster machines.” (Al-Fares 等, 2008, p. 63) 🔤第二种选择是利用商品以太网交换机和路由器实现集群机器之间的互联。🔤&lt;/p&gt;
&lt;p&gt;优点：&lt;/p&gt;
&lt;p&gt;“This approach supports a familiar management infrastructure along with unmodified applications, operating systems, and hardware.” (Al-Fares 等, 2008, p. 63) 🔤这种方法支持熟悉的管理基础设施以及未经修改的应用程序、操作系统和硬件。🔤&lt;/p&gt;
&lt;h3 id=&#34;desired-properties-for-a-dc-network-architecture直流网络架构的理想特性&#34;&gt;Desired Properties for a DC Network Architecture直流网络架构的理想特性&lt;/h3&gt;
&lt;p&gt;“Scalable interconnection bandwidth: it should be possible for an arbitrary host in the data center to communicate with any other host in the network at the full bandwidth of its local network interface.” (Al-Fares 等, 2008, p. 64) 🔤可扩展的互联带宽：数据中心的任意一台主机都应能以其本地网络接口的全部带宽与网络中的任何其他主机进行通信。🔤&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Scalable interconnection bandwidth: an arbitrary host can communicate with any other host at the full bandwidth of its local network interface (non-blocking).数据中心网络应该能够支持任意两个主机之间的全带宽通信，并且不会发生通信阻塞。这句话是数据中心网络设计的一个重要目标。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“Economies of scale: just as commodity personal computers became the basis for large-scale computing environments, we hope to leverage the same economies of scale to make cheap off-the-shelf Ethernet switches the basis for largescale data center networks.” (Al-Fares 等, 2008, p. 64) 🔤规模经济：正如商品化个人电脑成为大规模计算环境的基础一样，我们希望利用同样的规模经济，使廉价的现成以太网交换机成为大规模数据中心网络的基础。🔤&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Economies of scale: make cheap off-the-shelf Ethernet switches the basis for large scale data center networks&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;规模经济使廉价的现成以太网交换机成为大型数据中心网络的基础&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这句话的意思是，由于规模经济效应，廉价的现成以太网交换机在大型数据中心网络中得到了广泛应用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;规模经济效应&lt;/strong&gt;是指企业随着生产规模的扩大，单位产品的成本会降低的现象。在数据中心网络中，由于大型数据中心需要大量的以太网交换机，因此规模经济效应可以显著降低以太网交换机的成本。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“Backward compatibility: the entire system should be backward compatible with hosts running Ethernet and IP. That is, existing data centers, which almost universally leverage commodity Ethernet and run IP, should be able to take advantage of the new interconnect architecture with no modifications.” (Al-Fares 等, 2008, p. 64) 🔤向后兼容性：整个系统应向后兼容运行以太网和 IP 的主机。也就是说，几乎普遍利用商品以太网和运行 IP 的现有数据中心应能利用新的互连架构，而无需进行任何修改。🔤&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Backward compatibility: the entire system should be backward compatible with hosts running Ethernet and IP.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;向后兼容：整个系统应与运行以太网和 IP 的主机向后兼容&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这句话强调了系统需要与现有以太网和 IP 网络无缝集成的重要性。这确保了新主机和设备可以与遗留设备无缝通信，防止中断并确保平稳过渡到新系统。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conventional-data-center-network-topologies-传统数据中心网络拓扑结构&#34;&gt;Conventional Data Center Network Topologies 传统数据中心网络拓扑结构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.3460x5h9lgy0.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;br&gt;
(Al-Fares 等, 2008, p. 65)&lt;/p&gt;
&lt;p&gt;“Typical architectures today consist of either two- or three-level trees of switches or routers. A three-tiered design (see Figure 1) has a core tier in the root of the tree, an aggregation tier in the middle and an edge tier at the leaves of the tree.” (Al-Fares 等, 2008, p. 64) 🔤目前，典型的架构由两层或三层交换机或路由器树组成。三层设计（见图 1）的核心层位于树的根部，汇聚层位于树的中部，边缘层位于树的叶部。🔤&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心层（Core Tier）:&lt;/strong&gt; 核心层是网络的顶层，负责处理整个数据中心内的高级路由和转发。它通常拥有大量的高速连接，以支持大规模的数据传输。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;聚合层（Aggregation Tier）:&lt;/strong&gt; 聚合层位于核心层和边缘层之间，负责将来自边缘层的流量进行汇总和转发。这一层的存在有助于提高网络的可扩展性和性能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;边缘层（Edge Tier）:&lt;/strong&gt; 边缘层是网络结构的底层，位于树的末端，通常与终端设备直接相连。它处理与数据中心内部设备的直接通信，如服务器、存储设备等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“We assume the use of two types of switches, which represent the current high-end in both port density and bandwidth. The first, used at the edge of the tree, is a 48-port GigE switch, with four 10 GigE uplinks. For higher levels of a communication hierarchy, we consider 128-port 10 GigE switches. Both types of switches allow all directly connected hosts to communicate with one another at the full speed of their network interface.” (Al-Fares 等, 2008, p. 64) 🔤我们假设使用两种类型的交换机，它们在端口密度和带宽方面都代表了当前的高端水平。第一种是用于树边缘的 48 端口千兆以太网交换机，带有四个万兆以太网上行链路。对于通信层次结构的较高层次，我们考虑使用 128 端口万兆以太网交换机。这两种类型的交换机都允许所有直接连接的主机以其网络接口的全速相互通信。🔤&lt;/p&gt;
&lt;p&gt;Two types of switches:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;48-port GigE switch, with four 10 GigE uplinks, used at the edge of the tree&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这是一种用于数据中心网络结构边缘的交换机类型。&lt;/li&gt;
&lt;li&gt;具有48个千兆以太网端口，这些端口用于连接直接的终端设备（主机）。&lt;/li&gt;
&lt;li&gt;同时，它还有四个10千兆以太网的上行链路，连接到更高层次的网络结构，用于传输数据到聚合层。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;128-port 10 GigE switch for higher levels of a communication hierarchy&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这是另一种用于通信层次的较高级别的交换机类型。&lt;/li&gt;
&lt;li&gt;具有128个10千兆以太网端口，用于连接到。更多的底层交换机或直接连接到边缘层的终端设备&lt;/li&gt;
&lt;li&gt;这种交换机具有更大的端口密度和更高的带宽，适用于需要处理更多数据流量的网络层次。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;无论是48端口的千兆以太网交换机还是128端口的10千兆以太网交换机，它们都能够让直接连接的设备之间以最大速度进行通信。&lt;/p&gt;
&lt;h3 id=&#34;oversubscription&#34;&gt;“Oversubscription”&lt;/h3&gt;
&lt;p&gt;过度订阅是一种设计数据中心网络的策略，目的是降低总体设计成本。&lt;/p&gt;
&lt;p&gt;“We define the term oversubscription to be the ratio of the worst-case achievable aggregate bandwidth among the end hosts to the total bisection bandwidth of a particular communication topology.” (Al-Fares 等, 2008, p. 64) 🔤我们将 &amp;ldquo;超量订购 &amp;ldquo;定义为终端主机之间最坏情况下可实现的总带宽与特定通信拓扑的总带宽之比。🔤&lt;/p&gt;
&lt;p&gt;文中定义过度订阅为终端主机之间最坏情况下可实现的总带宽与特定通信拓扑的总带宽之比&lt;/p&gt;
&lt;p&gt;“An oversubscription of 1:1 indicates that all hosts may potentially communicate with arbitrary other hosts at the full bandwidth of their network interface (e.g., 1 Gb/s for commodity Ethernet designs).” (Al-Fares 等, 2008, p. 64)&lt;/p&gt;
&lt;p&gt;1:1的过度订阅表示所有主机可以潜在地以它们网络接口的完整带宽进行通信，例如，对于通用以太网设计，即1 Gb/s。&lt;/p&gt;
&lt;p&gt;“An oversubscription value of 5:1 means that only 20% of available host bandwidth is available for some communication patterns. Typical designs are oversubscribed by a factor of 2.5:1 (400 Mbps) to 8:1 (125 Mbps) [1].” (Al-Fares 等, 2008, p. 64) 🔤5:1 的超额订购值意味着只有 20% 的可用主机带宽可用于某些通信模式。典型设计的超额订购系数为 2.5:1 （400 Mbps）至 8:1（125 Mbps）[1]。🔤&lt;/p&gt;
&lt;p&gt;虽然 1 Gb/s 以太网的数据中心可以实现 1:1 的超量订阅，但这种设计的成本通常过高。&lt;/p&gt;
&lt;h3 id=&#34;multi-path-routing&#34;&gt;Multi-path Routing&lt;/h3&gt;
&lt;p&gt;“Delivering full bandwidth between arbitrary hosts in larger clusters requires a “multi-rooted” tree with multiple core switches (see Figure 1).” (Al-Fares 等, 2008, p. 64) 🔤要在大型集群中的任意主机之间提供全带宽，就需要一个具有多个核心交换机的 &amp;ldquo;多根 &amp;ldquo;树（见图 1）。🔤&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Multi-Rooted Tree (多根树):&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这表示网络拓扑中存在多个核心交换机，这些交换机在树的根部，以支持更多的路径选择。&lt;/p&gt;
&lt;p&gt;“To take advantage of multiple paths, ECMP performs static load splitting among flows.” (Al-Fares 等, 2008, p. 64) 🔤为了利用多条路径，ECMP 在流量之间执行静态负载分流。🔤&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ECMP (Equal-Cost Multi-Path):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ECMP 是一种多路径路由技术，旨在平均分担等代价路径上的流量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;它允许在多个等代价路径上进行流量的分发，以提高网络的利用率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ECMP 的实现对于路径的多样性有一定的限制，通常限制在 8-16 条路径之间。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;这可能不足以满足较大数据中心所需的高二分带宽，因为这限制了网络在不同路径上进行流量分发的灵活性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用 ECMP 时，考虑的路径数量成倍增加，导致路由表的条目数量也成倍增加。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;这会增加系统的成本，并可能导致查找延迟的增加。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cost&#34;&gt;Cost&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.6hpo115nvo80.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;br&gt;
(Al-Fares 等, 2008, p. 65)&lt;/p&gt;
&lt;p&gt;维持一个固定的oversubscription，cost会随规模急剧增加。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.3f9sf3zsqx80.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;
(Al-Fares 等, 2008, p. 65)&lt;/p&gt;
&lt;p&gt;大型集群中实现高带宽水平的现有技术会产生显著的成本，而基于 fat-tree 架构的集群互连在适度的成本下具有显著的潜力。&lt;/p&gt;
&lt;p&gt;使用最大的10千兆以太网（10 GigE）和通用千兆以太网（GigE）交换机构建具有1:1过度订阅的数据中心，以及该集群最多可支持27,648个主机&lt;/p&gt;
&lt;h2 id=&#34;-研究内容&#34;&gt;📊 研究内容&lt;/h2&gt;
&lt;hr&gt;
&lt;h3 id=&#34;fat-tree-based-solution&#34;&gt;Fat tree based solution&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.170gmczp1zmk.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;有k个pod，每个pod包含两层k/2个交换机。这样的结构使得网络具有层次化的特点。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在底层，每个k端口的交换机直接连接到k/2个主机。这确保了较低层次的直接主机连接。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;剩余的k/2个端口连接到层次结构中聚合层的k/2个端口。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在fattree拓扑中，存在**(k/2)^2**个k端口的核心交换机。每个核心交换机有k个端口，其中每个端口连接到k个pod之一。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;考虑一个fattree拓扑，其中有k个pod，每个pod有k/2个交换机，每个交换机有k个端口。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;任意两个主机可能位于不同的pod，因此可以通过连接这两个pod的多条路径进行通信。对于每个pod，存在(k/2)个交换机，因此在每个pod内也有(k/2)条不同的路径。因此，总的最短路径数为(k/2)²。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;每个核心交换机的第i个端口与第i个pod连接。这样的连接模式确保了每个pod都与所有核心交换机直接相连。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在每个pod的聚合层交换机上，与核心交换机的连接是以(k/2)的步幅进行的，即相邻的聚合层端口与核心交换机的连接是在(k/2)步幅上的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在这篇论文中，重点关注k值最多为48的设计。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;地址&#34;&gt;地址&lt;/h3&gt;
&lt;p&gt;“We allocate all the IP addresses in the network within the private 10.0.0.0/8 block. We follow the familiar quad-dotted form with the following conditions: The pod switches are given addresses of the form 10.pod.switch.1,wherepod denotes the pod number (in [0,k − 1]), and switch denotes the position of that switch in the pod (in [0,k−1], starting from left to right, bottom to top). We give core switches addresses of the form 10.k.j.i,wherej and i denote that switch’s coordinates in the (k/2)2 core switch grid (each in [1, (k/2)], starting from top-left). The address of a host follows from the pod switch it is connected to; hosts have addresses of the form: 10.pod.switch.ID,where ID is the host’s position in that subnet (in [2,k/2+1], starting from left to right). Therefore, each lower-level switch is responsible for a /24 subnet of k/2 hosts (for k&amp;lt;256). Figure 3 shows examples of this addressing scheme for a fat-tree corresponding to k =4.Even though this is relatively wasteful use of the available address space, it simplifies building the routing tables, as seen below. Nonetheless, this scheme scales up to 4.2M hosts.” (Al-Fares 等, 2008, p. 66)&lt;/p&gt;
&lt;p&gt;在网络中，我们将所有的IP地址分配在私有的10.0.0.0/8地址块中。我们按熟悉的四点形式进行分配，具体如下：pod交换机的地址形式为10.pod.switch.1，其中pod表示pod的编号（范围在[0, k-1]之间），switch表示该pod中交换机的位置（范围在[0, k-1]之间，从左到右，从下到上）。核心交换机的地址形式为10.k.j.i，其中j和i表示该交换机在(k/2) x (k/2)的核心交换机网格中的坐标（范围在[1, k/2]之间，从左上角开始）。主机的地址由其所连接的pod交换机产生；主机的地址形式为10.pod.switch.ID，其中ID是该子网中主机的位置（范围在[2, k/2+1]之间，从左到右）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;交换机地址的分配&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.5dvcbmzvvsk0.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;核心交换机的地址&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.5z1gc04j48w0.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;主机的地址&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.4jymzeht8pw0.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;算法&#34;&gt;算法&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.5l0mmva3bf40.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;z 在[k/2,k-1]的原因：pod里面的上层交换机&lt;/p&gt;
&lt;p&gt;最里面的第一个循环的意思是：给pod里面的上层交换机按顺序添加前缀&lt;/p&gt;
&lt;p&gt;第二个addprefix的意思是增加一个0.0.0.0/0的默认前缀&lt;/p&gt;
&lt;p&gt;第二个循环的意思是给主机添加特定前缀&lt;/p&gt;
&lt;p&gt;“The reason for the modulo shift in the outgoing port is to avoid traffic from different lower-layer switches addressed to a host with the same host ID going to the same upper-layer switch.” (Al-Fares 等, 2008, p. 68) 🔤出站端口之所以要进行模数转换，是为了避免从不同下层交换机发送到具有相同主机 ID 的主机的流量进入同一上层交换机。🔤&lt;/p&gt;
&lt;h4 id=&#34;生产核心交换机路由&#34;&gt;生产核心交换机路由&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.4mnx5fu38u80.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;br&gt;
(Al-Fares 等, 2008, p. 68)&lt;/p&gt;
&lt;p&gt;就是为每个核心交换机按顺序分配一个10.x.0.0/16的路由&lt;/p&gt;
&lt;h4 id=&#34;例子&#34;&gt;例子&lt;/h4&gt;
&lt;p&gt;从10.0.1.2到10.2.0.3&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.4zuwsxwbdfg0.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;源主机（10.0.1.1）的网关交换机只会匹配带有 /0 一级前缀的数据包，因此会根据该前缀的二级表中的主机 ID 字节转发数据包。在该表中，数据包匹配 0.0.0.3/8 后缀，指向端口 2 和交换机 10.0.2.1（i=3，z=1）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;端口2:（3-2+1)mod(4/2+4/2)=2&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.1xxg1yvi9xa8.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;为什么指向10.0.2.1？因为10.0.1.1到端口0和端口1指向向下的俩host，端口2指向10.0.2.1（从下到上，从左到右）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/Anonymity-0/Picgo@note_picture/img/image.1uorkw107ukg.webp&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;“Switch 10.0.2.1 also follows the same steps and forwards on port 3, connected to core switch 10.4.1.1” (Al-Fares 等, 2008, p. 68) 🔤交换机 10.0.2.1 也遵循相同步骤，在连接到核心交换机 10.4.1.2 的端口 3 上进行转发🔤&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;i=3，z=2，（3-2+2）mod（2+2）=3&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;因为目的地址在pod2，核心交换机10.4.1.2匹配10.2.0.0/16，端口2，指向10.2.2.1&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;10.2.2.1匹配到10.2.0.0/24，指向10.2.0.1&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;-研究结论&#34;&gt;🚩 研究结论&lt;/h2&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-感想--疑问&#34;&gt;📌 感想 &amp;amp; 疑问&lt;/h2&gt;
&lt;hr&gt;
&lt;h3 id=&#34;what-is-the-datacenter-network-what-is-the-desired-property-of-the-datacenter-network&#34;&gt;What is the datacenter network? What is the desired property of the datacenter network?&lt;/h3&gt;
&lt;p&gt;根据提供的信息，对于数据中心网络，论文[1]提出了一种基于可扩展性和通用性的架构。数据中心网络旨在支持大规模集群之间的通信，并具有以下期望特性：&lt;/p&gt;
&lt;p&gt;1. 可扩展性：数据中心网络需要能够支持数以千计甚至数以百万计的节点，并提供良好的吞吐量和性能。这是因为数据中心通常由大量服务器和计算资源组成。&lt;/p&gt;
&lt;p&gt;2. 低延迟：数据中心网络需要具备低延迟的特性，以确保快速和高效的数据传输。这对于网络中的实时应用和大数据处理等任务至关重要。&lt;/p&gt;
&lt;p&gt;3. 高带宽：数据中心网络需要具有高带宽，以处理大量数据的传输需求。这是因为数据中心中经常需要在节点之间进行大规模的数据传输和通信。&lt;/p&gt;
&lt;h3 id=&#34;what-is-the-traditional-three-tier-topology-for-the-datacenter-its-limitations&#34;&gt;What is the traditional three-tier topology for the datacenter, its limitations?&lt;/h3&gt;
&lt;p&gt;传统的数据中心网络采用三层架构，包括核心层、聚合层和接入层。核心层处理数据中心内部的高级路由功能，聚合层用于连接核心层和接入层，并提供流量聚合和负载均衡。接入层则负责连接终端设备和聚合层。然而，传统的三层架构在规模扩大时会面临一些限制，如带宽瓶颈和复杂的缆线布局，导致整体性能和可扩展性受限。&lt;/p&gt;
&lt;h3 id=&#34;how-fat-tree-differs-from-the-traditional-design-in&#34;&gt;How Fat-tree differs from the traditional design? In&lt;/h3&gt;
&lt;p&gt;Topology&lt;/p&gt;
&lt;p&gt;Fat-tree 是一种分层的树形结构，它通过增加接近根部的节点的带宽来解决网络瓶颈问题。在这种结构中，越靠近根部的节点（比如交换机）拥有更高的处理能力和更大的带宽。这种设计使得网络能够更好地扩展，并支持更多的终端节点。&lt;/p&gt;
&lt;p&gt;Addressing&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;IP 地址范围&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;所有的 IP 地址都分配在私有的 &lt;code&gt;10.0.0.0/8&lt;/code&gt; 地址块内。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pod 交换机地址&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个 Pod 交换机的 IP 地址格式为 &lt;code&gt;10.pod.switch.1&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;其中 &lt;code&gt;pod&lt;/code&gt; 是 Pod 编号，范围是 &lt;code&gt;[0, k-1]&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;switch&lt;/code&gt; 是该交换机在 Pod 内的位置，范围也是 &lt;code&gt;[0, k-1]&lt;/code&gt;，按照从左到右、从下到上的顺序。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;核心交换机地址&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;核心交换机的 IP 地址格式为 &lt;code&gt;10.k.j.i&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;j&lt;/code&gt; 和 &lt;code&gt;i&lt;/code&gt; 是交换机在核心交换机网格中的坐标，范围是 &lt;code&gt;[1, k/2]&lt;/code&gt;，从左上角开始。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;主机地址&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;连接到 Pod 交换机的主机的 IP 地址格式为 &lt;code&gt;10.pod.switch.ID&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ID&lt;/code&gt; 是主机在子网中的位置，范围是 &lt;code&gt;[2, k/2+1]&lt;/code&gt;，按照从左到右的顺序。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;子网管理&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个下级交换机管理一个包含 &lt;code&gt;k/2&lt;/code&gt; 台主机的 &lt;code&gt;/24&lt;/code&gt; 子网（当 &lt;code&gt;k&lt;/code&gt; 小于 256 时）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;routing-algorithm&#34;&gt;Routing algorithm&lt;/h3&gt;
&lt;p&gt;源 $ℎ1h1$ 到目的地 $ℎ2h2$ 的路由路径的例子。这个例子中，源地址是 10.0.1.2，目的地地址是 10.2.0.3。以下是每一跳的详细描述以及如何确定输出端口：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第一跳 - 网关交换机&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;源主机的网关交换机（10.0.1.1）首先匹配到 /0 第一级前缀，然后根据该前缀的二级表中的主机 ID 字节来转发数据包。在这个表中，数据包匹配到 0.0.0.3/8 后缀，指向端口 2 和交换机 10.0.2.1 (&lt;a class=&#34;link&#34; href=&#34;https://myaidrive.com/?r=c#/home?folder=&amp;amp;file=al-fares2008.pdf&amp;amp;pdfPage=6&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;页面 6&lt;/a&gt;)。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第二跳 - Pod 交换机&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;交换机 10.0.2.1 也执行相同的步骤，并通过连接到核心交换机 10.4.1.1 的端口 3 转发数据包。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第三跳 - 核心交换机&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;核心交换机匹配数据包到一个终止的 10.2.0.0/16 前缀，这个前缀指向目的地 Pod 2。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果目的地地址变成 10.2.0.2，路由路径将会有所不同。以下是基于文档中的两级路由表和网络拓扑的详细解释：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第一跳 - 网关交换机&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;源主机的网关交换机（假设为 10.0.1.1）首先匹配到 /0 第一级前缀。然后，它会根据该前缀的二级表中的主机 ID 字节来转发数据包。在这个表中，数据包匹配到的后缀将会是 0.0.0.2/8，这将决定数据包应该转发到的端口和下一个交换机。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第二跳 - Pod 交换机&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第二个交换机（例如 10.0.2.1）也会执行类似的步骤，根据其路由表中的匹配项来决定将数据包转发到哪个端口，以及下一个目标核心交换机。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第三跳 - 核心交换机&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;到达核心交换机（例如 10.4.1.1）后，它会匹配数据包到一个终止的 10.2.0.0/16 前缀。这个前缀指向目的地 Pod 2。核心交换机将根据其路由表决定将数据包转发到哪个 Pod 交换机。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;最后一跳 - 到达目的地&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 Pod 2 内，相应的交换机将根据其路由表来决定如何将数据包最终转发到目的地地址 10.2.0.2 的主机。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;问题&#34;&gt;问题&lt;/h3&gt;
&lt;p&gt;假设 Fattree 用10.0.0.0/8的地址空间进行编址，且不考虑单个交换机大小的物理限制。&lt;/p&gt;
&lt;p&gt;1. 该地址空间所能支持的最大 Fattree 有多少个pod，即K=&lt;/p&gt;
&lt;p&gt;首先，10.0.0.0/8的地址空间有&lt;/p&gt;
&lt;p&gt;$$2^{24}$$&lt;/p&gt;
&lt;p&gt;个IP地址，其中一个地址用于网络标识，一个地址用于广播，剩下的地址用于主机。&lt;/p&gt;
&lt;p&gt;$$\frac{k^3}{4} \leq 2^{24}-2$$&lt;/p&gt;
&lt;p&gt;k=406&lt;/p&gt;
&lt;p&gt;2.以下哪个数字是一个完整的Fattree 可能支持的主机数（）&lt;/p&gt;
&lt;p&gt;A. 4194304&lt;/p&gt;
&lt;p&gt;B. 2097152&lt;/p&gt;
&lt;p&gt;C.3906250&lt;/p&gt;
&lt;p&gt;D. 2916000&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于A选项（4194304），我们需要解方程 $\frac{k^3}{4}=4194304$。&lt;/li&gt;
&lt;li&gt;对于B选项（2097152），方程为 $\frac{k^3}{4}=2097152$。&lt;/li&gt;
&lt;li&gt;对于C选项（3906250），方程为 $\frac{k^3}{4}=3906250$。&lt;/li&gt;
&lt;li&gt;对于D选项（2916000），方程为 $\frac{k^3}{4}=2916000$。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们可以计算每个方程来找出正确的答案。&lt;/p&gt;
&lt;p&gt;根据计算结果：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于选项A（4194304），计算得到的k值约为256，是一个合理的偶数。&lt;/li&gt;
&lt;li&gt;对于选项B（2097152），计算得到的k值约为203.19，不是偶数。&lt;/li&gt;
&lt;li&gt;对于选项C（3906250），计算得到的k值约为250，是一个合理的偶数。&lt;/li&gt;
&lt;li&gt;对于选项D（2916000），计算得到的k值约为226.79，不是偶数。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于k必须是偶数，因此只有选项A和C的k值符合条件。但在Fat-tree拓扑中，k通常是2的幂次方，所以最符合条件的答案是选项A（4194304），其对应的k值为256。&lt;/p&gt;
&lt;p&gt;3. Fattree 用的是交换机连接，给每个交换机分配 IP地址的目的是&lt;/p&gt;
&lt;p&gt;“we introduce the concept of two-level route lookups to assist with multi-path routing across the fat-tree.” (Al-Fares 等, 2008, p. 66) 🔤我们引入了两级路由查找的概念，以帮助在胖树上进行多路径路由选择。🔤&lt;/p&gt;
&lt;p&gt;“Even though this is relatively wasteful use of the available address space, it simplifies building the routing tables, as seen below.” (Al-Fares 等, 2008, p. 66) 🔤尽管这相对浪费了可用地址空间，但却简化了路由表的构建，如下所示。🔤&lt;/p&gt;
&lt;p&gt;Fattree使用交换机连接，并给每个交换机分配IP地址的目的是为了实现数据中心的通信和路由功能。通过给交换机分配IP地址，可以在网络中对不同的主机进行定位和识别，实现数据包的转发和数据中心网络的路由控制。这样可以保证在数据中心网络中的每个交换机都能够准确地识别和转发数据包。此外，通过对不同交换机分配不同的IP地址，还可以构建网络拓扑和路由表，实现数据中心网络的高效通信和负载均衡。&lt;/p&gt;
&lt;h2 id=&#34;-理论推导&#34;&gt;🔬 理论推导&lt;/h2&gt;
&lt;hr&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/baidu_20163013/article/details/110004560&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/baidu_20163013/article/details/110004560&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/u012925450/article/details/108493968&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/u012925450/article/details/108493968&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/weixin_44639164/article/details/126950178?&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/weixin_44639164/article/details/126950178?&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
