---
title: RAG 技术入门
slug: getting-started-with-rag-technology-z1qoouz
url: /post/getting-started-with-rag-technology-z1qoouz.html
date: '2025-10-09 17:01:51+08:00'
lastmod: '2025-10-16 16:21:53+08:00'
toc: true
isCJKLanguage: true
---





‍

​**RAG（Retrieval-Augmented Generation）** ，即检索增强生成，是一种将检索和生成结合的强大AI技术，广泛应用于智能客服、问答系统以及知识库构建。本文将深入解析RAG的原理，详细讲解它是如何通过检索和生成两个环节来提升问答系统的效率与准确性。

### 一、RAG 工作原理概述

RAG的基本流程分为两个部分：**数据准备阶段（提问前）**  和 ​**回答生成阶段（提问后）** 。这两个部分的配合使得RAG可以高效地从海量数据中提取相关信息，并基于这些信息生成高质量的答案。

#### 数据准备阶段（提问前）

![image](https://raw.githubusercontent.com/Anonymity-0/Picgo/main/img/20251016143310.png)

1. ​**文档分片**：首先，文档或知识库会被分割成多个小片段。每个片段代表文档中的一个独立信息单元（例如：一段话、一段定义或一个问题解答）。这样做的目的是让系统能更灵活地对数据进行处理和检索。
2. ​**向量化（Embedding）** ：接下来，每个分片会通过一个嵌入模型（通常是专门的embedding模型）转化为一个向量。向量化是将文本数据转换为数学空间中的点，这样不同文本之间的相似性就能通过计算向量之间的距离来度量。
3. ​**向量存储（索引）** ：转化为向量的数据会被存储到一个向量数据库中。这个数据库专门用于高效存储和查询这些向量，支持快速的相似度计算。

#### 回答生成阶段（提问后）

![image](https://raw.githubusercontent.com/Anonymity-0/Picgo/main/img/20251016143334.png)

1. ​**用户问题向量化（Embedding）** ：用户提问后，系统会首先将用户的问题通过embedding模型转化为一个向量。
2. ​**召回（Recall）** ​：将用户问题的向量与向量数据库中的所有片段向量进行比对，查找出与问题最相关的几个片段。常见的相似度计算方法包括​**余弦相似度**​、**欧式距离**等。
3. ​**重排（Re-ranking）** ：召回的片段虽然相关性较高，但可能不完全准确。重排阶段通过更高精度的模型（例如CROSSENCODER）对召回的片段进行重新排序，选出最相关的几个片段。
4. ​**生成（Generation）** ：最终，将选出的片段和用户问题一起输入给生成模型（如GPT-4），生成最终的回答。

## 二、原理细节解析

### 1. 文本分片

文本分片的目的是将大段的文本划分成小的、语义相对独立的单元。这样做能够提高检索的效率和精度。例如，对于一个关于公司产品的手册，可以将每个产品的描述、功能、规格等部分单独划分为一个片段。每个片段都应具有独立的语义单位，确保检索时可以准确匹配相关内容。

![image](https://raw.githubusercontent.com/Anonymity-0/Picgo/main/img/20251016135828.png)

文本分片的过程并不是简单的将文档按行或段落划分，而是基于**语义**和**长度**的平衡。以下是常见的几种分片方法：

#### 1. **固定长度分片（Fixed-length Chunking）**

最简单的一种方法，是按照固定长度（通常按字符数或标记数）来切分文本。该方法的优点是操作简单、快速，但缺点是有可能打破文本的语义结构，导致分片内部缺乏上下文连贯性。

- ​**优点**：

  - 简单易懂，实施起来直接。
  - 易于控制每个片段的大小，避免过长的文本超出上下文窗口限制。
- ​**缺点**：

  - 分割后的片段可能没有明确的语义界限，导致信息碎片化，检索的精度较低。
  - 不利于处理带有复杂结构的文本（如长段落或复杂的说明文档）。

#### 2. **基于段落的分片（Paragraph-based Chunking）**

这种方法是基于文档的自然段落进行分片。每个片段对应一个自然段落，通常较短，且保留了段落的语义信息，适合描述单一话题或信息点的情况。

- ​**优点**：

  - 自然段落通常包含较为完整的信息，因此语义连贯性较强。
  - 对于描述单一主题的文本（如FAQ、公司手册）较为有效。
- ​**缺点**：

  - 如果段落过长，仍然可能超出上下文窗口的限制。
  - 对于复杂的文档结构或多主题文档，段落分割可能不够精确。

#### 3. **基于句子的分片（Sentence-based Chunking）**

在这种方法中，文本被拆分成一个个句子。这种方式可以在一定程度上保留文本的语义完整性，因为每个句子都是一个独立的语义单元，适用于那些信息较为简洁且独立的问题。

- ​**优点**：

  - 每个句子都是独立的信息单元，语义较为清晰，便于检索。
  - 可以有效避免句子之间的上下文丢失。
- ​**缺点**：

  - 如果问题涉及多句复杂的情境，单句的片段可能信息不足，导致生成模型无法给出准确答案。
  - 对于长文档或多层次的解释，句子分片可能会忽略上下文关系，影响答案质量。

#### 4. **基于主题或信息块的分片（Topic-based or Information Block Chunking）**

这种分片方法依据文档的主题或信息结构进行切分。例如，在产品手册中，可以按产品的功能、规格、使用方式等进行分割，确保每个片段围绕单一主题展开。

- ​**优点**：

  - 每个片段具有清晰的语义主题，能更精准地检索到相关信息。
  - 适合用于处理多主题、多内容的长文档，如百科全书、复杂的技术文档等。
- ​**缺点**：

  - 切分的过程需要依赖文本结构分析，较为复杂。
  - 对于没有明确结构的文本，可能需要额外的NLP技术（如主题建模）来辅助分割。

#### 5. **基于人工规则的分片（Rule-based Chunking）**

这种方法通过设定一些规则，按特定的标记、语法结构、词汇模式等对文本进行分片。例如，可以在标点符号（如句号、问号）后分割文本，或者通过机器学习模型检测文档中的重要信息单元。

- ​**优点**：

  - 可以针对特定需求进行定制化分片，灵活性较高。
  - 对于特定领域的文档（如法律、医学），能够精准地按照术语和格式进行切割。
- ​**缺点**：

  - 实现复杂，需要针对具体问题设计规则。
  - 对于文本变化较大的场景（如自然语言生成或长篇对话），可能效果不佳。

#### 6. **基于BERT或其他预训练模型的分片（Transformer-based Chunking）**

这种方法基于预训练的语言模型（如BERT）将文本分成具有语义一致性的片段。通过BERT等模型计算每个片段的语义相似度，将语义接近的内容聚合为一个片段。这种方法能够较为准确地捕捉到文本中的主题、意图和信息块。

- ​**优点**：

  - 能够捕捉更深层次的语义信息，避免了单纯按字符或句子分割的粗糙问题。
  - 适合用于语义较为复杂的任务，能提高检索的准确性。
- ​**缺点**：

  - 计算复杂度较高，需要更多的计算资源。
  - 需要依赖大量的语料和训练数据，适用于特定领域或需求。

‍

‍

### 2. 向量化（Embedding）

**Embedding**是自然语言处理中的关键技术之一，它将文本数据转化为向量表示，以便计算机可以理解和处理文本的语义信息。通过嵌入模型（如BERT、RoBERTa、DistilBERT等），文本被转化为固定维度的向量，这些向量在高维空间中表示文本的语义。

#### 向量的维度与信息量

向量的维度表示了其包含的特征数目，通常是几百到几千维。每个维度代表了文本的某个语义特征。维度越高，向量能够表示的语义信息就越丰富。但这也意味着：

- ​**计算复杂度增加**：较高的维度会增加计算的复杂度，尤其是在进行相似度计算时，处理大规模数据时可能会变得非常耗时。
- ​**维度与效率的平衡**：在实际应用中，通常需要在高维度表示和计算效率之间找到合适的平衡。维度越高，模型可以更精确地捕捉到文本之间的细微差别，但也可能会导致性能下降，尤其是在大规模数据处理时。

#### 向量化的好处

向量化使得文本数据可以通过数值化表示进行处理。具体来说，文本被转化为一组数值（向量），这些数值能够通过计算相似度来衡量文本之间的语义相似性。常见的相似度计算方法包括：

#### 向量化的技术实现

1. **BERT（Bidirectional Encoder Representations from Transformers）**   
    BERT 是一种基于 Transformer 的预训练语言模型，它可以通过双向上下文的学习获得丰富的文本表示。通过BERT模型，文本可以被转化为高维向量，表示其语义信息。
2. **RoBERTa（A Robustly Optimized BERT Pretraining Approach）**   
    RoBERTa 是对 BERT 的一种优化版本，通过改进预训练过程和使用更多数据，RoBERTa 提供了更强大的文本表示能力。它的嵌入效果通常比BERT更好，尤其是在需要处理长文本时。
3. **DistilBERT**  
    DistilBERT 是 BERT 的一个精简版本，它通过减少模型的参数数量，保持BERT的性能，同时提高计算效率。对于需要平衡效率和精度的应用场景，DistilBERT 是一个很好的选择。
4. **Sentence-BERT**  
    Sentence-BERT 是专门为句子级任务优化的 BERT 变体。它通过使用双塔架构（Bi-encoder）生成句子的嵌入，使得句子之间的相似度计算更为高效。它常用于文本相似度、语义搜索等应用。

#### 向量化应用实例：Hugging Face MTEB

Hugging Face 提供了一个名为 **MTEB (Multi-Task Embedding Benchmark)**  的平台，用于评估各种嵌入模型在不同任务中的表现。这个平台对比了多种嵌入模型，并提供了广泛的应用案例，如文本分类、文本相似度等任务的评估。

- ​**网址**​：[Hugging Face MTEB](https://huggingface.co/spaces/mteb/leaderboard)  
  该平台允许用户上传自己的数据并测试模型的表现，可以帮助开发者选择最适合的嵌入模型。

‍

### 3. 向量数据库与索引

向量数据库在处理RAG系统中起着至关重要的作用，它主要用于存储和管理文本的向量表示，并支持高效的相似度搜索。通过嵌入技术将文本转换为向量后，向量数据库便成了检索、存储和优化查询过程的核心组件。

![image](https://raw.githubusercontent.com/Anonymity-0/Picgo/main/img/20251016140240.png)

#### 向量数据库概述

向量数据库（Vector Database）是专门设计用于存储向量并支持高效的相似度查询的数据库。这类数据库与传统的关系型数据库不同，因为它们不仅存储数据本身（如文本、图像、音频等），还存储这些数据的向量表示，以便进行高效的相似度检索。

常见的向量数据库包括：

- ​**Faiss**：由Facebook AI Research开发的一个高效的相似度搜索库，支持大量高维向量数据的检索。
- ​**Pinecone**：是一个用于高效相似性搜索的云原生向量数据库，提供了简单易用的接口和高性能查询能力。

这些数据库通常能支持百万级甚至更多数据的检索，并且在高维数据上仍能维持较高的查询效率。

#### 向量数据库的主要功能

![image](https://raw.githubusercontent.com/Anonymity-0/Picgo/main/img/20251016140457.png)

1. **向量存储**  
    在向量数据库中，存储的不仅是文本的向量表示，还包括原始文本或数据。这一机制使得查询不仅可以基于向量相似度进行，还能在检索到相关的向量后，快速回溯到原始文本或数据，供后续生成模型或其他应用使用。

    - **文本向量存储**：将文本片段转化为固定维度的向量表示，并将其存储在向量数据库中。
    - ​**原始数据存储**：向量数据库同时存储原始文本或其他相关信息，使得查询返回的不仅是向量，还能快速提取到原始数据，提供更多上下文信息。
2. **高效检索**  
    向量数据库的核心功能之一是支持高效的向量搜索，能够快速找到与查询向量相似的片段。这是通过一些优化算法实现的，主要目标是减少计算开销，提高查询响应速度。

### 4. 召回（Recall）

召回阶段的核心任务是根据用户的提问，找出与其问题最相关的片段。召回操作是基于向量相似度来计算的。在这一阶段，系统通过将用户问题转化为向量，并与向量数据库中的片段进行比较，选出与问题最相似的片段。

![image](https://raw.githubusercontent.com/Anonymity-0/Picgo/main/img/20251016142837.png)

- **召回策略**：召回通常选出多个片段，并且在这个阶段的目标是快速找到相关的片段，而不要求极高的准确性。召回阶段的计算速度要求较高，因此使用的相似度计算方法如余弦相似度通常是计算成本较低的。

![image](https://raw.githubusercontent.com/Anonymity-0/Picgo/main/img/20251016142919.png)

#### 向量相似度计算方法

1. **余弦相似度（Cosine Similarity）**   
    余弦相似度计算的是两个向量之间夹角的余弦值。计算公式为：  
    [  
    \\text{Cosine Similarity}(A, B) \= \\frac{A \\cdot B}{|A| |B|}  
    ]  
    其中，(A \\cdot B) 是向量A与B的点积，(|A|) 和 (|B|) 是它们的欧几里得范数（即模长）。夹角越小（即余弦值越接近1），表示两个向量越相似。

    - ​**优点**：不受向量大小的影响，主要衡量两个向量的方向相似性。
    - ​**应用**：在文本相似度、信息检索、推荐系统中广泛使用。
2. **欧式距离（Euclidean Distance）**   
    欧式距离计算的是两个向量之间的直线距离。计算公式为：  
    [  
    \\text{Euclidean Distance}(A, B) \= \\sqrt{\\sum\_{i\=1}\^n (A\_i - B\_i)\^2}  
    ]  
    其中，(A\_i) 和 (B\_i) 是向量A和B在第i维上的值。欧式距离越小，表示两个向量越相似。

    - ​**优点**：计算直观，适合于度量点之间的真实距离。
    - ​**应用**：通常用于聚类分析、距离度量问题。
3. **曼哈顿距离（Manhattan Distance）**   
    曼哈顿距离计算的是两个向量在每个维度上的差值总和。公式为：  
    [  
    \\text{Manhattan Distance}(A, B) \= \\sum\_{i\=1}\^n |A\_i - B\_i|  
    ]  
    其中，(|A\_i - B\_i|) 是向量A和B在第i维上的差值的绝对值。

    - ​**优点**：在某些高维数据中，曼哈顿距离比欧式距离表现得更为稳定，尤其在数据分布较稀疏时。
    - ​**应用**：常用于高维数据的相似度计算、聚类等。

---

#### 5. 重排（Re-ranking）

重排阶段通过更精确的模型对召回的片段进行排序，以确保从召回结果中选择出最相关的内容。常见的重排模型是​**CROSSENCODER**，它是一个双向编码器，可以将用户问题和召回的片段一起输入，计算二者的相似度。虽然计算代价较高，但它能提供比召回阶段更精确的排序结果。

- **Cross-Encoder模型**：该模型通常比传统的向量检索方法（如Bi-Encoder）准确度更高，因为它在对问题和片段进行相似度计算时考虑了更多的上下文信息。尽管计算成本较高，但它能显著提高召回结果的准确性。

![image](https://raw.githubusercontent.com/Anonymity-0/Picgo/main/img/20251016143100.png)

**为什么不直接在召回直接选top3？**

**召回阶段**负责从大规模文档库中迅速选出潜在相关的片段，而**重排阶段**则通过更精确的模型对召回结果进行深度排序，确保选择最相关的片段。这两者是互补的，召回保证了检索的广度和效率，而重排则确保了答案的准确性和上下文的合理性。

因此，​**不能直接在召回阶段选Top 3**​，因为召回和重排的逻辑不同，重排阶段通过​**更多上下文信息的理解和计算**，能显著提升结果的质量。

#### 6. 生成（Generation）

生成阶段是RAG的最后一步，生成模型（如GPT-4）接收到用户的问题和相关片段后，基于这些信息生成一个自然语言答案。生成的答案会结合用户问题和从知识库中提取的相关内容。

- **如何生成答案**：生成模型会使用上下文信息来回答用户的问题。它不仅参考了召回和重排阶段选出的片段，还根据用户的提问来调整答案的内容和表达方式。

![image](https://raw.githubusercontent.com/Anonymity-0/Picgo/main/img/20251016143247.png)

---

### 三、RAG的技术优势

1. ​**高效处理大规模知识库**：传统的生成模型（如GPT）很难处理大量的文档和数据，因为它们的上下文窗口有限。RAG通过检索相关片段来扩展模型的知识面，提高了处理大规模知识库的能力。
2. ​**提高回答准确性**：通过召回和重排机制，RAG可以准确地从大量候选片段中选出最相关的内容，从而提高回答的准确性。
3. ​**灵活性**：RAG可以灵活地应对各种不同类型的问题和知识库，不仅限于固定的结构化数据，还能处理复杂的文本信息。

---

‍
